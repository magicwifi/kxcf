{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 173315: expected 18 fields, saw 20\\n'\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_user = pd.read_csv('data/table1_user',encoding='utf-8',index_col = False, delimiter='\\t')\n",
    "train_job = pd.read_csv(\"data/table2_jd\",delimiter=\"\\t\",error_bad_lines=False)\n",
    "train_action = pd.read_csv(\"data/table3_action\",delimiter=\"\\t\")\n",
    "train_action['mix_sat']  = train_action['satisfied']*10+train_action['delivered']*3\n",
    "train_action.loc[train_action.mix_sat==13,'mix_sat'] =10\n",
    "test_action = pd.read_csv(\"data/zhaopin_round1_user_exposure_A_20190723\",delim_whitespace=True)\n",
    "test_user = pd.read_csv(\"data/user_ToBePredicted\",delimiter=\"\\t\")\n",
    "test_big_table = pd.merge(test_action,test_user,how=\"inner\",on=\"user_id\")\n",
    "test_big_table = pd.merge(test_big_table,train_job,how=\"inner\",on=\"jd_no\")\n",
    "train_big_table = pd.merge(train_action,train_user,how=\"inner\",on=\"user_id\")\n",
    "train_big_table = pd.merge(train_big_table,train_job,how=\"inner\",on=\"jd_no\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_big_table.drop(columns=[\"company_name\",\"max_edu_level\",\"is_mangerial\",\"resume_language_required\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(citys,index):\n",
    "    city_list = citys.split(\",\")\n",
    "    if index < len(city_list):\n",
    "        city = city_list[index]\n",
    "        if city != \"-\":\n",
    "            city = int(city)\n",
    "        else:\n",
    "            city = -1\n",
    "    else:\n",
    "        city = -1\n",
    "    return city\n",
    "\n",
    "def exp_in_desc(exp,desc):\n",
    "    if str(exp) == \"nan\":\n",
    "        exp = \"\"\n",
    "    exps = exp.split(\"|\")\n",
    "    num = 0\n",
    "    for item in exps:\n",
    "        if item in desc:\n",
    "            num+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year_dict = {\n",
    "    305: 4,\n",
    "    -1:-1,\n",
    "    1:1,\n",
    "    103:2,\n",
    "    0:0,\n",
    "    510:7,\n",
    "    1099:10,\n",
    "    399:4,\n",
    "    599:7,\n",
    "    199:1,\n",
    "    299:2,\n",
    "    110:1\n",
    "}\n",
    "degree_dict = {\n",
    "    \"初中\":1,\n",
    "    \"中技\":2,\n",
    "    \"高中\":3,\n",
    "    \"中专\":3,\n",
    "    \"大专\":4,\n",
    "    \"本科\":5,\n",
    "    \"硕士\":6,\n",
    "    \"博士\":7,\n",
    "    \"EMBA\":7,\n",
    "    \"MBA\":6,\n",
    "    \"其他\":0,\n",
    "    \"请选择\":0,\n",
    "    \"\\\\N\":0,\n",
    "    \"na\":0\n",
    "}\n",
    "min_salary_dict = {\n",
    "    100002000:1000,\n",
    "    400106000:4001,\n",
    "    0:0,\n",
    "    200104000:2001,\n",
    "    600108000:6001,\n",
    "    800110000:8001,\n",
    "    1000115000:10001,\n",
    "    2500199999:25001,\n",
    "    1500125000:15001,\n",
    "    3500150000:35001,\n",
    "    70001100000:70001,\n",
    "    1000:0,\n",
    "    100001150000:100001,\n",
    "    2500135000:25001,\n",
    "    5000170000:50001\n",
    "}\n",
    "max_salary_dict = {\n",
    "    100002000:2000,\n",
    "    400106000:6000,\n",
    "    0:0,\n",
    "    200104000:4000,\n",
    "    600108000:8000,\n",
    "    800110000:10000,\n",
    "    1000115000:15000,\n",
    "    2500199999:99999,\n",
    "    1500125000:25000,\n",
    "    3500150000:50000,\n",
    "    70001100000:100000,\n",
    "    1000:1000,\n",
    "    100001150000:150000,\n",
    "    2500135000:35000,\n",
    "    5000170000:70000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(df):\n",
    "    df[\"desire_jd_city_1\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=0))\n",
    "    df[\"desire_jd_city_2\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=1))\n",
    "    df[\"desire_jd_city_3\"] = df[\"desire_jd_city_id\"].apply(partial(extract_city,index=2))\n",
    "    df[\"desire_jd_city_num\"] = df[[\"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\"]].sum(axis=1)\n",
    "    \n",
    "    df[\"city_equal_desired_city_1\"] = df[\"desire_jd_city_1\"]==df[\"city\"]\n",
    "    df[\"city_equal_desired_city_2\"] = df[\"desire_jd_city_2\"]==df[\"city\"]\n",
    "    df[\"city_equal_desired_city_3\"] = df[\"desire_jd_city_3\"]==df[\"city\"]\n",
    "    \n",
    "    df[\"work_years\"] = 2019-df[\"start_work_date\"].apply(lambda x : 2018 if x==\"-\" else int(x))\n",
    "    \n",
    "    \n",
    "    df[\"desire_min_salary\"] = df[\"desire_jd_salary_id\"].apply(lambda x: min_salary_dict[x])\n",
    "    df[\"desire_max_salary\"] = df[\"desire_jd_salary_id\"].apply(lambda x: max_salary_dict[x])\n",
    "    df[\"desire_salary_diff\"] = df[\"desire_max_salary\"]-df[\"desire_min_salary\"]\n",
    "    \n",
    "    df[\"min_years\"] = df[\"min_years\"].apply(lambda x: min_year_dict[x])\n",
    "    \n",
    "    df[\"work_years_statisfied\"] = df[\"work_years\"].astype(int) > df[\"min_years\"]\n",
    "    \n",
    "    df[\"salary_large_than_desire\"] = df[\"desire_min_salary\"] > df[\"min_salary\"]\n",
    "    \n",
    "    df[\"cur_salary_min\"] = df[\"cur_salary_id\"].apply(lambda x: min_salary_dict[int(x if str.isnumeric(x) else \"0\")])\n",
    "    df[\"cur_salary_max\"] = df[\"cur_salary_id\"].apply(lambda x: max_salary_dict[int(x if str.isnumeric(x) else \"0\")])\n",
    "    \n",
    "    df[\"salary_large_than_cur\"] = df[\"cur_salary_min\"] > df[\"min_salary\"]\n",
    "    \n",
    "    df[\"cur_degree_id\"] = df[\"cur_degree_id\"].fillna(\"na\").apply(lambda x:degree_dict[x.strip()])\n",
    "    \n",
    "    df[\"job_description_len\"] = df[\"job_description\"].apply(len)\n",
    "    \n",
    "    df[\"experience_num\"] = df[\"experience\"].apply(lambda x: len(str(x).split(\"|\")) if str(x) != \"nan\" else 0)\n",
    "    \n",
    "    df[\"min_edu_level\"] = df[\"min_edu_level\"].fillna(\"na\").apply(lambda x:degree_dict[x.strip()])\n",
    "    exp_in_desc_num = []\n",
    "    for idx, data in df.iterrows():\n",
    "        exp_in_desc_num.append(exp_in_desc(data[\"experience\"],data[\"job_description\"]))\n",
    "    df[\"exp_in_desc_num\"] = exp_in_desc_num\n",
    "    \n",
    "#     \"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "#          \"cur_degree_id\",\"city\",\"jd_sub_type\",\n",
    "#          \"max_salary\",\"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "#          \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"work_years_statisfied\"\n",
    "    cross_feature_tuple = [(\"live_city_id\",\"city\"),(\"live_city_id\",\"desire_jd_city_1\"),(\"cur_industry_id\",\"jd_sub_type\"),\n",
    "                          (\"cur_jd_type\",\"jd_sub_type\"),(\"cur_salary_id\",\"cur_degree_id\"),(\"city\",\"jd_sub_type\"),\n",
    "                          (\"jd_sub_type\",\"min_salary\"),(\"jd_sub_type\",\"max_salary\"),(\"jd_sub_type\",\"is_travel\"),\n",
    "                          (\"min_years\",\"jd_sub_type\"),(\"jd_sub_type\",\"require_nums\")]\n",
    "    cross_feature_names = list(feature[0]+\"&\"+feature[1] for feature in cross_feature_tuple)\n",
    "    print(\"create cross features\",cross_feature_names)\n",
    "    for idx,(fa,fb) in enumerate(cross_feature_tuple):\n",
    "        df[cross_feature_names[idx]] = df[fa].astype(str)+df[fb].astype(str)\n",
    "    return cross_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create cross features ['live_city_id&city', 'live_city_id&desire_jd_city_1', 'cur_industry_id&jd_sub_type', 'cur_jd_type&jd_sub_type', 'cur_salary_id&cur_degree_id', 'city&jd_sub_type', 'jd_sub_type&min_salary', 'jd_sub_type&max_salary', 'jd_sub_type&is_travel', 'min_years&jd_sub_type', 'jd_sub_type&require_nums']\n",
      "create cross features ['live_city_id&city', 'live_city_id&desire_jd_city_1', 'cur_industry_id&jd_sub_type', 'cur_jd_type&jd_sub_type', 'cur_salary_id&cur_degree_id', 'city&jd_sub_type', 'jd_sub_type&min_salary', 'jd_sub_type&max_salary', 'jd_sub_type&is_travel', 'min_years&jd_sub_type', 'jd_sub_type&require_nums']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['live_city_id&city',\n",
       " 'live_city_id&desire_jd_city_1',\n",
       " 'cur_industry_id&jd_sub_type',\n",
       " 'cur_jd_type&jd_sub_type',\n",
       " 'cur_salary_id&cur_degree_id',\n",
       " 'city&jd_sub_type',\n",
       " 'jd_sub_type&min_salary',\n",
       " 'jd_sub_type&max_salary',\n",
       " 'jd_sub_type&is_travel',\n",
       " 'min_years&jd_sub_type',\n",
       " 'jd_sub_type&require_nums']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "cross_feature_names = fe(train_big_table)\n",
    "fe(test_big_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm as tqdm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_big_table = pd.concat([train_big_table,test_big_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select(target,*df_list):\n",
    "    result = []\n",
    "    cat_features = [\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "         \"cur_degree_id\",\"city\",\"jd_sub_type\",\n",
    "         \"max_salary\",\"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "         \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"work_years_statisfied\"]+cross_feature_names\n",
    "    lbl_dict = {}\n",
    "    for f in cat_features:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(all_big_table[f].astype(str))\n",
    "        lbl_dict[f] = lbl\n",
    "    for df in df_list:\n",
    "        features = [\"live_city_id\",\"desire_jd_salary_id\",\"cur_industry_id\",\"cur_jd_type\",\"cur_salary_id\",\n",
    "             \"cur_degree_id\",\"birthday\",\"city\",\"jd_sub_type\",\"require_nums\",\n",
    "             \"max_salary\",\"min_salary\",\"is_travel\",\"min_years\",\"min_edu_level\",\n",
    "             \"desire_jd_city_1\",\"desire_jd_city_2\",\"desire_jd_city_3\",\"exp_in_desc_num\",\n",
    "                   \"city_equal_desired_city_1\",\"city_equal_desired_city_2\",\"city_equal_desired_city_3\",\n",
    "                   \"desire_min_salary\",\"desire_max_salary\",\"salary_large_than_desire\",\"cur_salary_min\",\n",
    "                   \"cur_salary_max\",\"salary_large_than_cur\",\"job_description_len\",\"experience_num\",\"work_years_statisfied\",\"work_years\",\"desire_jd_city_num\",\"desire_salary_diff\"]+cross_feature_names\n",
    "\n",
    "        x = df[features]\n",
    "        if target in df.columns:\n",
    "            y = df[target]\n",
    "        else:\n",
    "            y = None\n",
    "        for f in cat_features:\n",
    "            lbl = lbl_dict[f]\n",
    "            x[f] = lbl.transform(x[f].astype(str))\n",
    "        result.append((x,y))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(param=dict(n_estimators=1000,metric=\"map\",colsample_bytree=0.2,max_depth=7,importance_type=\"gain\")\n",
    "                   ,n_folds=5,target=\"mix_sat\"):\n",
    "    train_users = train_big_table[\"user_id\"].unique()\n",
    "    folds = KFold(n_folds,shuffle=True,random_state=42)\n",
    "    models = []\n",
    "    test_pred = np.zeros(test_big_table.shape[0])\n",
    "    scores = []\n",
    "    for idx,(train_idx,valid_idx) in enumerate(folds.split(train_users)):\n",
    "        t_user = train_users[train_idx]\n",
    "        v_user = train_users[valid_idx]\n",
    "        train_data = train_big_table[train_big_table[\"user_id\"].isin(t_user)]\n",
    "        valid_data = train_big_table[train_big_table[\"user_id\"].isin(v_user)]\n",
    "        train_group = train_data.groupby(\"user_id\",as_index=False).count()[\"mix_sat\"].values\n",
    "        valid_group = valid_data.groupby(\"user_id\",as_index=False).count()[\"mix_sat\"].values\n",
    "        test_group = test_big_table.groupby(\"user_id\",as_index=False).count()[\"jd_no\"].values\n",
    "        \n",
    "        result = feature_select(target,train_data,valid_data,test_big_table)\n",
    "        t_x,t_y = result[0]\n",
    "        v_x,v_y = result[1]\n",
    "        test_x,_ = result[2]\n",
    "        model = lgb.LGBMRanker(**param)\n",
    "        print(\"Fold\",idx,\"-\"*30)\n",
    "        model.fit(t_x,t_y,group=train_group,eval_set=[(t_x,t_y),(v_x,v_y)],eval_group=[train_group,valid_group],early_stopping_rounds=100,verbose=10,\n",
    "                  callbacks=[lgb.reset_parameter(learning_rate=lambda x: 0.01)]\n",
    "                 )\n",
    "        models.append(model)\n",
    "        test_pred += model.predict(test_x)/n_folds\n",
    "        scores.append(model.best_score_[\"valid_1\"][\"map@1\"])\n",
    "    print(\"mean score\",np.mean(scores))\n",
    "    return models,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.254727\tvalid_1's map@1: 0.208009\n",
      "[20]\ttraining's map@1: 0.266685\tvalid_1's map@1: 0.206897\n",
      "[30]\ttraining's map@1: 0.27475\tvalid_1's map@1: 0.196885\n",
      "[40]\ttraining's map@1: 0.275584\tvalid_1's map@1: 0.202447\n",
      "[50]\ttraining's map@1: 0.283092\tvalid_1's map@1: 0.195773\n",
      "[60]\ttraining's map@1: 0.281424\tvalid_1's map@1: 0.19911\n",
      "[70]\ttraining's map@1: 0.284205\tvalid_1's map@1: 0.196885\n",
      "[80]\ttraining's map@1: 0.283092\tvalid_1's map@1: 0.197998\n",
      "[90]\ttraining's map@1: 0.287542\tvalid_1's map@1: 0.20356\n",
      "[100]\ttraining's map@1: 0.291157\tvalid_1's map@1: 0.204672\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's map@1: 0.230812\tvalid_1's map@1: 0.211346\n",
      "Fold 1 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.23832\tvalid_1's map@1: 0.194661\n",
      "[20]\ttraining's map@1: 0.24277\tvalid_1's map@1: 0.202447\n",
      "[30]\ttraining's map@1: 0.253059\tvalid_1's map@1: 0.205784\n",
      "[40]\ttraining's map@1: 0.254171\tvalid_1's map@1: 0.210234\n",
      "[50]\ttraining's map@1: 0.264182\tvalid_1's map@1: 0.213571\n",
      "[60]\ttraining's map@1: 0.264461\tvalid_1's map@1: 0.208009\n",
      "[70]\ttraining's map@1: 0.268076\tvalid_1's map@1: 0.208009\n",
      "[80]\ttraining's map@1: 0.2703\tvalid_1's map@1: 0.208009\n",
      "[90]\ttraining's map@1: 0.274194\tvalid_1's map@1: 0.19911\n",
      "[100]\ttraining's map@1: 0.275028\tvalid_1's map@1: 0.205784\n",
      "[110]\ttraining's map@1: 0.278087\tvalid_1's map@1: 0.211346\n",
      "[120]\ttraining's map@1: 0.282258\tvalid_1's map@1: 0.213571\n",
      "[130]\ttraining's map@1: 0.285039\tvalid_1's map@1: 0.212458\n",
      "[140]\ttraining's map@1: 0.28921\tvalid_1's map@1: 0.210234\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's map@1: 0.260289\tvalid_1's map@1: 0.220245\n",
      "Fold 2 ------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\ttraining's map@1: 0.262236\tvalid_1's map@1: 0.209121\n",
      "[20]\ttraining's map@1: 0.263626\tvalid_1's map@1: 0.209121\n",
      "[30]\ttraining's map@1: 0.267519\tvalid_1's map@1: 0.213571\n",
      "[40]\ttraining's map@1: 0.268354\tvalid_1's map@1: 0.213571\n",
      "[50]\ttraining's map@1: 0.272803\tvalid_1's map@1: 0.214683\n",
      "[60]\ttraining's map@1: 0.278087\tvalid_1's map@1: 0.216908\n",
      "[70]\ttraining's map@1: 0.280868\tvalid_1's map@1: 0.215795\n",
      "[80]\ttraining's map@1: 0.284205\tvalid_1's map@1: 0.213571\n",
      "[90]\ttraining's map@1: 0.282536\tvalid_1's map@1: 0.21802\n",
      "[100]\ttraining's map@1: 0.286707\tvalid_1's map@1: 0.222469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-db564531f521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mix_sat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_split_gain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-5a2dc4a7dcf8>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(param, n_folds, target)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         model.fit(t_x,t_y,group=train_group,eval_set=[(t_x,t_y),(v_x,v_y)],eval_group=[train_group,valid_group],early_stopping_rounds=100,verbose=10,\n\u001b[0;32m---> 26\u001b[0;31m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                  )\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_group, eval_metric, eval_at, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    855\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                     \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m                                     callbacks=callbacks)\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \"\"\"\n\u001b[0;32m-> 1958\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models,pred = cross_validate(target=\"mix_sat\",param=dict(n_estimators=1000,num_leaves=128,metric=\"map\",subsample=0.8,min_split_gain=10,colsample_bytree=0.6,max_depth=7,importance_type=\"gain\"),n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
